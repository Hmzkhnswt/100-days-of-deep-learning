{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rank</th>\n",
       "      <th>Youtuber</th>\n",
       "      <th>subscribers</th>\n",
       "      <th>video views</th>\n",
       "      <th>category</th>\n",
       "      <th>Title</th>\n",
       "      <th>uploads</th>\n",
       "      <th>Country</th>\n",
       "      <th>Abbreviation</th>\n",
       "      <th>channel_type</th>\n",
       "      <th>...</th>\n",
       "      <th>subscribers_for_last_30_days</th>\n",
       "      <th>created_year</th>\n",
       "      <th>created_month</th>\n",
       "      <th>created_date</th>\n",
       "      <th>Gross tertiary education enrollment (%)</th>\n",
       "      <th>Population</th>\n",
       "      <th>Unemployment rate</th>\n",
       "      <th>Urban_population</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>T-Series</td>\n",
       "      <td>245000000</td>\n",
       "      <td>2.280000e+11</td>\n",
       "      <td>Music</td>\n",
       "      <td>T-Series</td>\n",
       "      <td>20082</td>\n",
       "      <td>India</td>\n",
       "      <td>IN</td>\n",
       "      <td>Music</td>\n",
       "      <td>...</td>\n",
       "      <td>2000000.0</td>\n",
       "      <td>2006.0</td>\n",
       "      <td>Mar</td>\n",
       "      <td>13.0</td>\n",
       "      <td>28.1</td>\n",
       "      <td>1.366418e+09</td>\n",
       "      <td>5.36</td>\n",
       "      <td>471031528.0</td>\n",
       "      <td>20.593684</td>\n",
       "      <td>78.962880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>YouTube Movies</td>\n",
       "      <td>170000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>Film &amp; Animation</td>\n",
       "      <td>youtubemovies</td>\n",
       "      <td>1</td>\n",
       "      <td>United States</td>\n",
       "      <td>US</td>\n",
       "      <td>Games</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2006.0</td>\n",
       "      <td>Mar</td>\n",
       "      <td>5.0</td>\n",
       "      <td>88.2</td>\n",
       "      <td>3.282395e+08</td>\n",
       "      <td>14.70</td>\n",
       "      <td>270663028.0</td>\n",
       "      <td>37.090240</td>\n",
       "      <td>-95.712891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>MrBeast</td>\n",
       "      <td>166000000</td>\n",
       "      <td>2.836884e+10</td>\n",
       "      <td>Entertainment</td>\n",
       "      <td>MrBeast</td>\n",
       "      <td>741</td>\n",
       "      <td>United States</td>\n",
       "      <td>US</td>\n",
       "      <td>Entertainment</td>\n",
       "      <td>...</td>\n",
       "      <td>8000000.0</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>Feb</td>\n",
       "      <td>20.0</td>\n",
       "      <td>88.2</td>\n",
       "      <td>3.282395e+08</td>\n",
       "      <td>14.70</td>\n",
       "      <td>270663028.0</td>\n",
       "      <td>37.090240</td>\n",
       "      <td>-95.712891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Cocomelon - Nursery Rhymes</td>\n",
       "      <td>162000000</td>\n",
       "      <td>1.640000e+11</td>\n",
       "      <td>Education</td>\n",
       "      <td>Cocomelon - Nursery Rhymes</td>\n",
       "      <td>966</td>\n",
       "      <td>United States</td>\n",
       "      <td>US</td>\n",
       "      <td>Education</td>\n",
       "      <td>...</td>\n",
       "      <td>1000000.0</td>\n",
       "      <td>2006.0</td>\n",
       "      <td>Sep</td>\n",
       "      <td>1.0</td>\n",
       "      <td>88.2</td>\n",
       "      <td>3.282395e+08</td>\n",
       "      <td>14.70</td>\n",
       "      <td>270663028.0</td>\n",
       "      <td>37.090240</td>\n",
       "      <td>-95.712891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>SET India</td>\n",
       "      <td>159000000</td>\n",
       "      <td>1.480000e+11</td>\n",
       "      <td>Shows</td>\n",
       "      <td>SET India</td>\n",
       "      <td>116536</td>\n",
       "      <td>India</td>\n",
       "      <td>IN</td>\n",
       "      <td>Entertainment</td>\n",
       "      <td>...</td>\n",
       "      <td>1000000.0</td>\n",
       "      <td>2006.0</td>\n",
       "      <td>Sep</td>\n",
       "      <td>20.0</td>\n",
       "      <td>28.1</td>\n",
       "      <td>1.366418e+09</td>\n",
       "      <td>5.36</td>\n",
       "      <td>471031528.0</td>\n",
       "      <td>20.593684</td>\n",
       "      <td>78.962880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>990</th>\n",
       "      <td>991</td>\n",
       "      <td>Natan por Aï¿</td>\n",
       "      <td>12300000</td>\n",
       "      <td>9.029610e+09</td>\n",
       "      <td>Sports</td>\n",
       "      <td>Natan por Aï¿</td>\n",
       "      <td>1200</td>\n",
       "      <td>Brazil</td>\n",
       "      <td>BR</td>\n",
       "      <td>Entertainment</td>\n",
       "      <td>...</td>\n",
       "      <td>700000.0</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>Feb</td>\n",
       "      <td>12.0</td>\n",
       "      <td>51.3</td>\n",
       "      <td>2.125594e+08</td>\n",
       "      <td>12.08</td>\n",
       "      <td>183241641.0</td>\n",
       "      <td>-14.235004</td>\n",
       "      <td>-51.925280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>991</th>\n",
       "      <td>992</td>\n",
       "      <td>Free Fire India Official</td>\n",
       "      <td>12300000</td>\n",
       "      <td>1.674410e+09</td>\n",
       "      <td>People &amp; Blogs</td>\n",
       "      <td>Free Fire India Official</td>\n",
       "      <td>1500</td>\n",
       "      <td>India</td>\n",
       "      <td>IN</td>\n",
       "      <td>Games</td>\n",
       "      <td>...</td>\n",
       "      <td>300000.0</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>Sep</td>\n",
       "      <td>14.0</td>\n",
       "      <td>28.1</td>\n",
       "      <td>1.366418e+09</td>\n",
       "      <td>5.36</td>\n",
       "      <td>471031528.0</td>\n",
       "      <td>20.593684</td>\n",
       "      <td>78.962880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>992</th>\n",
       "      <td>993</td>\n",
       "      <td>Panda</td>\n",
       "      <td>12300000</td>\n",
       "      <td>2.214684e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HybridPanda</td>\n",
       "      <td>2452</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>GB</td>\n",
       "      <td>Games</td>\n",
       "      <td>...</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>2006.0</td>\n",
       "      <td>Sep</td>\n",
       "      <td>11.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>6.683440e+07</td>\n",
       "      <td>3.85</td>\n",
       "      <td>55908316.0</td>\n",
       "      <td>55.378051</td>\n",
       "      <td>-3.435973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>993</th>\n",
       "      <td>994</td>\n",
       "      <td>RobTopGames</td>\n",
       "      <td>12300000</td>\n",
       "      <td>3.741235e+08</td>\n",
       "      <td>Gaming</td>\n",
       "      <td>RobTopGames</td>\n",
       "      <td>39</td>\n",
       "      <td>Sweden</td>\n",
       "      <td>SE</td>\n",
       "      <td>Games</td>\n",
       "      <td>...</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>May</td>\n",
       "      <td>9.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>1.028545e+07</td>\n",
       "      <td>6.48</td>\n",
       "      <td>9021165.0</td>\n",
       "      <td>60.128161</td>\n",
       "      <td>18.643501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>994</th>\n",
       "      <td>995</td>\n",
       "      <td>Make Joke Of</td>\n",
       "      <td>12300000</td>\n",
       "      <td>2.129774e+09</td>\n",
       "      <td>Comedy</td>\n",
       "      <td>Make Joke Of</td>\n",
       "      <td>62</td>\n",
       "      <td>India</td>\n",
       "      <td>IN</td>\n",
       "      <td>Comedy</td>\n",
       "      <td>...</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>Aug</td>\n",
       "      <td>1.0</td>\n",
       "      <td>28.1</td>\n",
       "      <td>1.366418e+09</td>\n",
       "      <td>5.36</td>\n",
       "      <td>471031528.0</td>\n",
       "      <td>20.593684</td>\n",
       "      <td>78.962880</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>995 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     rank                    Youtuber  subscribers   video views   \n",
       "0       1                    T-Series    245000000  2.280000e+11  \\\n",
       "1       2              YouTube Movies    170000000  0.000000e+00   \n",
       "2       3                     MrBeast    166000000  2.836884e+10   \n",
       "3       4  Cocomelon - Nursery Rhymes    162000000  1.640000e+11   \n",
       "4       5                   SET India    159000000  1.480000e+11   \n",
       "..    ...                         ...          ...           ...   \n",
       "990   991               Natan por Aï¿     12300000  9.029610e+09   \n",
       "991   992    Free Fire India Official     12300000  1.674410e+09   \n",
       "992   993                       Panda     12300000  2.214684e+09   \n",
       "993   994                 RobTopGames     12300000  3.741235e+08   \n",
       "994   995                Make Joke Of     12300000  2.129774e+09   \n",
       "\n",
       "             category                       Title  uploads         Country   \n",
       "0               Music                    T-Series    20082           India  \\\n",
       "1    Film & Animation               youtubemovies        1   United States   \n",
       "2       Entertainment                     MrBeast      741   United States   \n",
       "3           Education  Cocomelon - Nursery Rhymes      966   United States   \n",
       "4               Shows                   SET India   116536           India   \n",
       "..                ...                         ...      ...             ...   \n",
       "990            Sports               Natan por Aï¿     1200          Brazil   \n",
       "991    People & Blogs    Free Fire India Official     1500           India   \n",
       "992               NaN                 HybridPanda     2452  United Kingdom   \n",
       "993            Gaming                 RobTopGames       39          Sweden   \n",
       "994            Comedy                Make Joke Of       62           India   \n",
       "\n",
       "    Abbreviation   channel_type  ...  subscribers_for_last_30_days   \n",
       "0             IN          Music  ...                     2000000.0  \\\n",
       "1             US          Games  ...                           NaN   \n",
       "2             US  Entertainment  ...                     8000000.0   \n",
       "3             US      Education  ...                     1000000.0   \n",
       "4             IN  Entertainment  ...                     1000000.0   \n",
       "..           ...            ...  ...                           ...   \n",
       "990           BR  Entertainment  ...                      700000.0   \n",
       "991           IN          Games  ...                      300000.0   \n",
       "992           GB          Games  ...                        1000.0   \n",
       "993           SE          Games  ...                      100000.0   \n",
       "994           IN         Comedy  ...                      100000.0   \n",
       "\n",
       "     created_year  created_month  created_date   \n",
       "0          2006.0            Mar          13.0  \\\n",
       "1          2006.0            Mar           5.0   \n",
       "2          2012.0            Feb          20.0   \n",
       "3          2006.0            Sep           1.0   \n",
       "4          2006.0            Sep          20.0   \n",
       "..            ...            ...           ...   \n",
       "990        2017.0            Feb          12.0   \n",
       "991        2018.0            Sep          14.0   \n",
       "992        2006.0            Sep          11.0   \n",
       "993        2012.0            May           9.0   \n",
       "994        2017.0            Aug           1.0   \n",
       "\n",
       "     Gross tertiary education enrollment (%)    Population  Unemployment rate   \n",
       "0                                       28.1  1.366418e+09               5.36  \\\n",
       "1                                       88.2  3.282395e+08              14.70   \n",
       "2                                       88.2  3.282395e+08              14.70   \n",
       "3                                       88.2  3.282395e+08              14.70   \n",
       "4                                       28.1  1.366418e+09               5.36   \n",
       "..                                       ...           ...                ...   \n",
       "990                                     51.3  2.125594e+08              12.08   \n",
       "991                                     28.1  1.366418e+09               5.36   \n",
       "992                                     60.0  6.683440e+07               3.85   \n",
       "993                                     67.0  1.028545e+07               6.48   \n",
       "994                                     28.1  1.366418e+09               5.36   \n",
       "\n",
       "     Urban_population   Latitude  Longitude  \n",
       "0         471031528.0  20.593684  78.962880  \n",
       "1         270663028.0  37.090240 -95.712891  \n",
       "2         270663028.0  37.090240 -95.712891  \n",
       "3         270663028.0  37.090240 -95.712891  \n",
       "4         471031528.0  20.593684  78.962880  \n",
       "..                ...        ...        ...  \n",
       "990       183241641.0 -14.235004 -51.925280  \n",
       "991       471031528.0  20.593684  78.962880  \n",
       "992        55908316.0  55.378051  -3.435973  \n",
       "993         9021165.0  60.128161  18.643501  \n",
       "994       471031528.0  20.593684  78.962880  \n",
       "\n",
       "[995 rows x 28 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"D:\\#DATA Science\\Deep Learning\\Deep Learning Practice\\Global YouTube Statistics.csv\", encoding=\"latin-1\")\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rank                                         0\n",
       "Youtuber                                     0\n",
       "subscribers                                  0\n",
       "video views                                  0\n",
       "category                                    46\n",
       "Title                                        0\n",
       "uploads                                      0\n",
       "Country                                    122\n",
       "Abbreviation                               122\n",
       "channel_type                                30\n",
       "video_views_rank                             1\n",
       "country_rank                               116\n",
       "channel_type_rank                           33\n",
       "video_views_for_the_last_30_days            56\n",
       "lowest_monthly_earnings                      0\n",
       "highest_monthly_earnings                     0\n",
       "lowest_yearly_earnings                       0\n",
       "highest_yearly_earnings                      0\n",
       "subscribers_for_last_30_days               337\n",
       "created_year                                 5\n",
       "created_month                                5\n",
       "created_date                                 5\n",
       "Gross tertiary education enrollment (%)    123\n",
       "Population                                 123\n",
       "Unemployment rate                          123\n",
       "Urban_population                           123\n",
       "Latitude                                   123\n",
       "Longitude                                  123\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column_name in data.columns:\n",
    "    if data[column_name].isnull().sum() > 100:\n",
    "        data.drop(columns=[column_name], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rank                                 0\n",
       "Youtuber                             0\n",
       "subscribers                          0\n",
       "video views                          0\n",
       "category                            46\n",
       "Title                                0\n",
       "uploads                              0\n",
       "channel_type                        30\n",
       "video_views_rank                     1\n",
       "channel_type_rank                   33\n",
       "video_views_for_the_last_30_days    56\n",
       "lowest_monthly_earnings              0\n",
       "highest_monthly_earnings             0\n",
       "lowest_yearly_earnings               0\n",
       "highest_yearly_earnings              0\n",
       "created_year                         5\n",
       "created_month                        5\n",
       "created_date                         5\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['rank', 'Youtuber', 'subscribers', 'video views', 'category', 'Title',\n",
       "       'uploads', 'channel_type', 'video_views_rank', 'channel_type_rank',\n",
       "       'video_views_for_the_last_30_days', 'lowest_monthly_earnings',\n",
       "       'highest_monthly_earnings', 'lowest_yearly_earnings',\n",
       "       'highest_yearly_earnings', 'created_year', 'created_month',\n",
       "       'created_date'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "imputer = SimpleImputer(strategy='most_frequent')\n",
    "data = imputer.fit_transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = ['rank', 'Youtuber', 'subscribers', 'video views', 'category', 'Title',\n",
    "       'uploads', 'channel_type', 'video_views_rank', 'channel_type_rank',\n",
    "       'video_views_for_the_last_30_days', 'lowest_monthly_earnings',\n",
    "       'highest_monthly_earnings', 'lowest_yearly_earnings',\n",
    "       'highest_yearly_earnings', 'created_year', 'created_month',\n",
    "       'created_date']\n",
    "df  =pd.DataFrame(data, columns=column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rank</th>\n",
       "      <th>Youtuber</th>\n",
       "      <th>subscribers</th>\n",
       "      <th>video views</th>\n",
       "      <th>category</th>\n",
       "      <th>Title</th>\n",
       "      <th>uploads</th>\n",
       "      <th>channel_type</th>\n",
       "      <th>video_views_rank</th>\n",
       "      <th>channel_type_rank</th>\n",
       "      <th>video_views_for_the_last_30_days</th>\n",
       "      <th>lowest_monthly_earnings</th>\n",
       "      <th>highest_monthly_earnings</th>\n",
       "      <th>lowest_yearly_earnings</th>\n",
       "      <th>highest_yearly_earnings</th>\n",
       "      <th>created_year</th>\n",
       "      <th>created_month</th>\n",
       "      <th>created_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>T-Series</td>\n",
       "      <td>245000000</td>\n",
       "      <td>228000000000.0</td>\n",
       "      <td>Music</td>\n",
       "      <td>T-Series</td>\n",
       "      <td>20082</td>\n",
       "      <td>Music</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2258000000.0</td>\n",
       "      <td>564600.0</td>\n",
       "      <td>9000000.0</td>\n",
       "      <td>6800000.0</td>\n",
       "      <td>108400000.0</td>\n",
       "      <td>2006.0</td>\n",
       "      <td>Mar</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>YouTube Movies</td>\n",
       "      <td>170000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Film &amp; Animation</td>\n",
       "      <td>youtubemovies</td>\n",
       "      <td>1</td>\n",
       "      <td>Games</td>\n",
       "      <td>4055159.0</td>\n",
       "      <td>7423.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.58</td>\n",
       "      <td>2006.0</td>\n",
       "      <td>Mar</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>MrBeast</td>\n",
       "      <td>166000000</td>\n",
       "      <td>28368841870.0</td>\n",
       "      <td>Entertainment</td>\n",
       "      <td>MrBeast</td>\n",
       "      <td>741</td>\n",
       "      <td>Entertainment</td>\n",
       "      <td>48.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1348000000.0</td>\n",
       "      <td>337000.0</td>\n",
       "      <td>5400000.0</td>\n",
       "      <td>4000000.0</td>\n",
       "      <td>64700000.0</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>Feb</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Cocomelon - Nursery Rhymes</td>\n",
       "      <td>162000000</td>\n",
       "      <td>164000000000.0</td>\n",
       "      <td>Education</td>\n",
       "      <td>Cocomelon - Nursery Rhymes</td>\n",
       "      <td>966</td>\n",
       "      <td>Education</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1975000000.0</td>\n",
       "      <td>493800.0</td>\n",
       "      <td>7900000.0</td>\n",
       "      <td>5900000.0</td>\n",
       "      <td>94800000.0</td>\n",
       "      <td>2006.0</td>\n",
       "      <td>Sep</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>SET India</td>\n",
       "      <td>159000000</td>\n",
       "      <td>148000000000.0</td>\n",
       "      <td>Shows</td>\n",
       "      <td>SET India</td>\n",
       "      <td>116536</td>\n",
       "      <td>Entertainment</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1824000000.0</td>\n",
       "      <td>455900.0</td>\n",
       "      <td>7300000.0</td>\n",
       "      <td>5500000.0</td>\n",
       "      <td>87500000.0</td>\n",
       "      <td>2006.0</td>\n",
       "      <td>Sep</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  rank                    Youtuber subscribers     video views   \n",
       "0    1                    T-Series   245000000  228000000000.0  \\\n",
       "1    2              YouTube Movies   170000000             0.0   \n",
       "2    3                     MrBeast   166000000   28368841870.0   \n",
       "3    4  Cocomelon - Nursery Rhymes   162000000  164000000000.0   \n",
       "4    5                   SET India   159000000  148000000000.0   \n",
       "\n",
       "           category                       Title uploads   channel_type   \n",
       "0             Music                    T-Series   20082          Music  \\\n",
       "1  Film & Animation               youtubemovies       1          Games   \n",
       "2     Entertainment                     MrBeast     741  Entertainment   \n",
       "3         Education  Cocomelon - Nursery Rhymes     966      Education   \n",
       "4             Shows                   SET India  116536  Entertainment   \n",
       "\n",
       "  video_views_rank channel_type_rank video_views_for_the_last_30_days   \n",
       "0              1.0               1.0                     2258000000.0  \\\n",
       "1        4055159.0            7423.0                             12.0   \n",
       "2             48.0               1.0                     1348000000.0   \n",
       "3              2.0               1.0                     1975000000.0   \n",
       "4              3.0               2.0                     1824000000.0   \n",
       "\n",
       "  lowest_monthly_earnings highest_monthly_earnings lowest_yearly_earnings   \n",
       "0                564600.0                9000000.0              6800000.0  \\\n",
       "1                     0.0                     0.05                   0.04   \n",
       "2                337000.0                5400000.0              4000000.0   \n",
       "3                493800.0                7900000.0              5900000.0   \n",
       "4                455900.0                7300000.0              5500000.0   \n",
       "\n",
       "  highest_yearly_earnings created_year created_month created_date  \n",
       "0             108400000.0       2006.0           Mar         13.0  \n",
       "1                    0.58       2006.0           Mar          5.0  \n",
       "2              64700000.0       2012.0           Feb         20.0  \n",
       "3              94800000.0       2006.0           Sep          1.0  \n",
       "4              87500000.0       2006.0           Sep         20.0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(995, 18)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df[\"channel_type\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df[\"category\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['subscribers', 'video views','video_views_for_the_last_30_days', 'lowest_monthly_earnings',\n",
    "       'highest_monthly_earnings', 'lowest_yearly_earnings',\n",
    "       'highest_yearly_earnings','video_views_rank', 'channel_type_rank']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(995, 9)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[12.67419283, 15.38317373,  5.14962002, ...,  7.3471669 ,\n",
       "        -0.40834362, -0.37588659],\n",
       "       [ 8.39271013, -0.78273762, -0.40789577, ..., -0.51354319,\n",
       "         2.56044323,  3.49876952],\n",
       "       [ 8.16436439,  1.22870178,  2.90987715, ...,  4.17822749,\n",
       "        -0.40830921, -0.37588659],\n",
       "       ...,\n",
       "       [-0.60982083, -0.62570959, -0.40773081, ..., -0.51331118,\n",
       "        -0.31389961,  0.25109562],\n",
       "       [-0.60982083, -0.7562111 , -0.39836827, ..., -0.5000698 ,\n",
       "        -0.3826388 , -0.34038718],\n",
       "       [-0.60982083, -0.63173002, -0.34882565, ..., -0.4265243 ,\n",
       "        -0.40500011, -0.35343844]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scale = StandardScaler()\n",
    "scale.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(df[\"channel_type\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "trainx, testx, trainy, testy = train_test_split(X,y,test_size=0.2,random_state=41)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainx = trainx.astype(np.float32)\n",
    "trainy = trainy.astype(np.int32)\n",
    "testx = testx.astype(np.float32)\n",
    "testy = testy.astype(np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.layers import Dense\n",
    "from keras.models import Sequential\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 500)               5000      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 250)               125250    \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 125)               31375     \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 100)               12600     \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 56)                5656      \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 28)                1596      \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 14)                406       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 181883 (710.48 KB)\n",
      "Trainable params: 181883 (710.48 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(500, activation='relu', input_dim = 9))\n",
    "model.add(Dense(250, activation='relu'))\n",
    "model.add(Dense(125, activation='relu'))\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dense(56, activation='relu'))\n",
    "model.add(Dense(28, activation='relu'))\n",
    "model.add(Dense(14,activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "25/25 [==============================] - 2s 19ms/step - loss: 63924660.0000 - accuracy: 0.1922 - val_loss: 8974295.0000 - val_accuracy: 0.2111\n",
      "Epoch 2/100\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 2274420.5000 - accuracy: 0.0854 - val_loss: 692.0567 - val_accuracy: 0.0402\n",
      "Epoch 3/100\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 32988.6172 - accuracy: 0.2148 - val_loss: 16.9194 - val_accuracy: 0.3266\n",
      "Epoch 4/100\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 8784.1436 - accuracy: 0.3342 - val_loss: 108554.6328 - val_accuracy: 0.3216\n",
      "Epoch 5/100\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 10805.8730 - accuracy: 0.3367 - val_loss: 74417.1172 - val_accuracy: 0.3216\n",
      "Epoch 6/100\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 9344.9004 - accuracy: 0.3354 - val_loss: 129337.4766 - val_accuracy: 0.3216\n",
      "Epoch 7/100\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 19351.9414 - accuracy: 0.3379 - val_loss: 93459.2500 - val_accuracy: 0.3216\n",
      "Epoch 8/100\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 10114.0576 - accuracy: 0.3392 - val_loss: 10302.7119 - val_accuracy: 0.3216\n",
      "Epoch 9/100\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 10519.1309 - accuracy: 0.3367 - val_loss: 2010.8140 - val_accuracy: 0.3216\n",
      "Epoch 10/100\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 4564.4204 - accuracy: 0.3392 - val_loss: 55762.2461 - val_accuracy: 0.3216\n",
      "Epoch 11/100\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 3129.5054 - accuracy: 0.3392 - val_loss: 65732.3047 - val_accuracy: 0.3216\n",
      "Epoch 12/100\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 2299.5979 - accuracy: 0.3392 - val_loss: 56994.1953 - val_accuracy: 0.3216\n",
      "Epoch 13/100\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 1554.8593 - accuracy: 0.3392 - val_loss: 21559.5059 - val_accuracy: 0.3216\n",
      "Epoch 14/100\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 1082.4996 - accuracy: 0.3379 - val_loss: 31.3887 - val_accuracy: 0.3216\n",
      "Epoch 15/100\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 1421.4185 - accuracy: 0.3367 - val_loss: 32106.1113 - val_accuracy: 0.3216\n",
      "Epoch 16/100\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 6651.4521 - accuracy: 0.3354 - val_loss: 2.4159 - val_accuracy: 0.3266\n",
      "Epoch 17/100\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 20288.8320 - accuracy: 0.3329 - val_loss: 18345.6934 - val_accuracy: 0.3216\n",
      "Epoch 18/100\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 5841.5068 - accuracy: 0.3367 - val_loss: 315164.9688 - val_accuracy: 0.3216\n",
      "Epoch 19/100\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 3641.4993 - accuracy: 0.3367 - val_loss: 298293.4062 - val_accuracy: 0.3216\n",
      "Epoch 20/100\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 37320.7148 - accuracy: 0.3354 - val_loss: 472226.9062 - val_accuracy: 0.3216\n",
      "Epoch 21/100\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 25692.0508 - accuracy: 0.3367 - val_loss: 229730.9531 - val_accuracy: 0.3216\n",
      "Epoch 22/100\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 30118.3145 - accuracy: 0.3354 - val_loss: 132105.8125 - val_accuracy: 0.3216\n",
      "Epoch 23/100\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 16832.6465 - accuracy: 0.3392 - val_loss: 145510.2500 - val_accuracy: 0.3216\n",
      "Epoch 24/100\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 16078.0742 - accuracy: 0.3379 - val_loss: 194448.9062 - val_accuracy: 0.3216\n",
      "Epoch 25/100\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 8720.0146 - accuracy: 0.3392 - val_loss: 304381.0312 - val_accuracy: 0.3216\n",
      "Epoch 26/100\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 24045.2832 - accuracy: 0.3392 - val_loss: 189874.2969 - val_accuracy: 0.3216\n",
      "Epoch 27/100\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 27930.3320 - accuracy: 0.3392 - val_loss: 194222.3750 - val_accuracy: 0.3216\n",
      "Epoch 28/100\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 10675.6318 - accuracy: 0.3392 - val_loss: 134609.5781 - val_accuracy: 0.3216\n",
      "Epoch 29/100\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 1227.0420 - accuracy: 0.3379 - val_loss: 55513.3125 - val_accuracy: 0.3216\n",
      "Epoch 30/100\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 2.2635 - accuracy: 0.3405 - val_loss: 47800.2344 - val_accuracy: 0.3216\n",
      "Epoch 31/100\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 2.2541 - accuracy: 0.3405 - val_loss: 47536.5195 - val_accuracy: 0.3216\n",
      "Epoch 32/100\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 2.2450 - accuracy: 0.3405 - val_loss: 47516.2578 - val_accuracy: 0.3216\n",
      "Epoch 33/100\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 2.2362 - accuracy: 0.3405 - val_loss: 47514.6992 - val_accuracy: 0.3216\n",
      "Epoch 34/100\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 2.2275 - accuracy: 0.3405 - val_loss: 47514.5898 - val_accuracy: 0.3216\n",
      "Epoch 35/100\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 2.2192 - accuracy: 0.3405 - val_loss: 47514.5742 - val_accuracy: 0.3216\n",
      "Epoch 36/100\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 2.2111 - accuracy: 0.3405 - val_loss: 47514.5664 - val_accuracy: 0.3216\n",
      "Epoch 37/100\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 2.2033 - accuracy: 0.3405 - val_loss: 47514.5625 - val_accuracy: 0.3216\n",
      "Epoch 38/100\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 2.1958 - accuracy: 0.3405 - val_loss: 47514.5469 - val_accuracy: 0.3216\n",
      "Epoch 39/100\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 2.1883 - accuracy: 0.3405 - val_loss: 47514.5430 - val_accuracy: 0.3216\n",
      "Epoch 40/100\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 2.1814 - accuracy: 0.3405 - val_loss: 47514.5391 - val_accuracy: 0.3216\n",
      "Epoch 41/100\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 2.1745 - accuracy: 0.3405 - val_loss: 47514.5391 - val_accuracy: 0.3216\n",
      "Epoch 42/100\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 2.1678 - accuracy: 0.3405 - val_loss: 47514.5312 - val_accuracy: 0.3216\n",
      "Epoch 43/100\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 2.1614 - accuracy: 0.3405 - val_loss: 47514.5234 - val_accuracy: 0.3216\n",
      "Epoch 44/100\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 2.1553 - accuracy: 0.3405 - val_loss: 47514.5195 - val_accuracy: 0.3216\n",
      "Epoch 45/100\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 2.1492 - accuracy: 0.3405 - val_loss: 47514.5195 - val_accuracy: 0.3216\n",
      "Epoch 46/100\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 2.1436 - accuracy: 0.3405 - val_loss: 47514.5039 - val_accuracy: 0.3216\n",
      "Epoch 47/100\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 2.1380 - accuracy: 0.3405 - val_loss: 47514.5039 - val_accuracy: 0.3216\n",
      "Epoch 48/100\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 2.1326 - accuracy: 0.3405 - val_loss: 47514.4922 - val_accuracy: 0.3216\n",
      "Epoch 49/100\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 2.1275 - accuracy: 0.3405 - val_loss: 47514.4805 - val_accuracy: 0.3216\n",
      "Epoch 50/100\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 2.1225 - accuracy: 0.3405 - val_loss: 47514.4766 - val_accuracy: 0.3216\n",
      "Epoch 51/100\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 2.1177 - accuracy: 0.3405 - val_loss: 47514.4727 - val_accuracy: 0.3216\n",
      "Epoch 52/100\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 2.1131 - accuracy: 0.3405 - val_loss: 47514.4727 - val_accuracy: 0.3216\n",
      "Epoch 53/100\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 2.1087 - accuracy: 0.3405 - val_loss: 47514.4688 - val_accuracy: 0.3216\n",
      "Epoch 54/100\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 2.1044 - accuracy: 0.3405 - val_loss: 47514.4688 - val_accuracy: 0.3216\n",
      "Epoch 55/100\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 2.1004 - accuracy: 0.3405 - val_loss: 47514.4453 - val_accuracy: 0.3216\n",
      "Epoch 56/100\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 2.0963 - accuracy: 0.3405 - val_loss: 47514.4453 - val_accuracy: 0.3216\n",
      "Epoch 57/100\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 2.0924 - accuracy: 0.3405 - val_loss: 47514.4453 - val_accuracy: 0.3216\n",
      "Epoch 58/100\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 2.0890 - accuracy: 0.3405 - val_loss: 47514.4453 - val_accuracy: 0.3216\n",
      "Epoch 59/100\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 2.0854 - accuracy: 0.3405 - val_loss: 47514.4414 - val_accuracy: 0.3216\n",
      "Epoch 60/100\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 2.0819 - accuracy: 0.3405 - val_loss: 47514.4414 - val_accuracy: 0.3216\n",
      "Epoch 61/100\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 2.0787 - accuracy: 0.3405 - val_loss: 47514.4414 - val_accuracy: 0.3216\n",
      "Epoch 62/100\n",
      "25/25 [==============================] - 0s 12ms/step - loss: 2.0756 - accuracy: 0.3405 - val_loss: 47514.4336 - val_accuracy: 0.3216\n",
      "Epoch 63/100\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 2.0727 - accuracy: 0.3405 - val_loss: 47514.4336 - val_accuracy: 0.3216\n",
      "Epoch 64/100\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 2.0697 - accuracy: 0.3405 - val_loss: 47514.4258 - val_accuracy: 0.3216\n",
      "Epoch 65/100\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 2.0670 - accuracy: 0.3405 - val_loss: 47514.4219 - val_accuracy: 0.3216\n",
      "Epoch 66/100\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 2.0642 - accuracy: 0.3405 - val_loss: 47514.4180 - val_accuracy: 0.3216\n",
      "Epoch 67/100\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 2.0617 - accuracy: 0.3405 - val_loss: 47514.4180 - val_accuracy: 0.3216\n",
      "Epoch 68/100\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 2.0593 - accuracy: 0.3405 - val_loss: 47514.4180 - val_accuracy: 0.3216\n",
      "Epoch 69/100\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 2.0569 - accuracy: 0.3405 - val_loss: 47514.4180 - val_accuracy: 0.3216\n",
      "Epoch 70/100\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 2.0547 - accuracy: 0.3405 - val_loss: 47514.4102 - val_accuracy: 0.3216\n",
      "Epoch 71/100\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 2.0525 - accuracy: 0.3405 - val_loss: 47514.4102 - val_accuracy: 0.3216\n",
      "Epoch 72/100\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 2.0504 - accuracy: 0.3405 - val_loss: 47514.4102 - val_accuracy: 0.3216\n",
      "Epoch 73/100\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 2.0484 - accuracy: 0.3405 - val_loss: 47514.4102 - val_accuracy: 0.3216\n",
      "Epoch 74/100\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 2.0465 - accuracy: 0.3405 - val_loss: 47514.4102 - val_accuracy: 0.3216\n",
      "Epoch 75/100\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 2.0446 - accuracy: 0.3405 - val_loss: 47514.4062 - val_accuracy: 0.3216\n",
      "Epoch 76/100\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 2.0429 - accuracy: 0.3405 - val_loss: 47514.4023 - val_accuracy: 0.3216\n",
      "Epoch 77/100\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 2.0411 - accuracy: 0.3405 - val_loss: 47514.3984 - val_accuracy: 0.3216\n",
      "Epoch 78/100\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 2.0395 - accuracy: 0.3405 - val_loss: 47514.3984 - val_accuracy: 0.3216\n",
      "Epoch 79/100\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 2.0380 - accuracy: 0.3405 - val_loss: 47514.3984 - val_accuracy: 0.3216\n",
      "Epoch 80/100\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 2.0365 - accuracy: 0.3405 - val_loss: 47514.3984 - val_accuracy: 0.3216\n",
      "Epoch 81/100\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 2.0350 - accuracy: 0.3405 - val_loss: 47514.3906 - val_accuracy: 0.3216\n",
      "Epoch 82/100\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 2.0336 - accuracy: 0.3405 - val_loss: 47514.3867 - val_accuracy: 0.3216\n",
      "Epoch 83/100\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 2.0322 - accuracy: 0.3405 - val_loss: 47514.3867 - val_accuracy: 0.3216\n",
      "Epoch 84/100\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 2.0310 - accuracy: 0.3405 - val_loss: 47514.3867 - val_accuracy: 0.3216\n",
      "Epoch 85/100\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 2.0298 - accuracy: 0.3405 - val_loss: 47514.3867 - val_accuracy: 0.3216\n",
      "Epoch 86/100\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 2.0285 - accuracy: 0.3405 - val_loss: 47514.3867 - val_accuracy: 0.3216\n",
      "Epoch 87/100\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 2.0275 - accuracy: 0.3405 - val_loss: 47514.3906 - val_accuracy: 0.3216\n",
      "Epoch 88/100\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 2.0264 - accuracy: 0.3405 - val_loss: 47514.3906 - val_accuracy: 0.3216\n",
      "Epoch 89/100\n",
      "25/25 [==============================] - 0s 14ms/step - loss: 2.0253 - accuracy: 0.3405 - val_loss: 47514.3906 - val_accuracy: 0.3216\n",
      "Epoch 90/100\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 2.0243 - accuracy: 0.3405 - val_loss: 47514.3906 - val_accuracy: 0.3216\n",
      "Epoch 91/100\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 2.0233 - accuracy: 0.3405 - val_loss: 47514.3906 - val_accuracy: 0.3216\n",
      "Epoch 92/100\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 2.0224 - accuracy: 0.3405 - val_loss: 47514.3906 - val_accuracy: 0.3216\n",
      "Epoch 93/100\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 2.0215 - accuracy: 0.3405 - val_loss: 47514.3906 - val_accuracy: 0.3216\n",
      "Epoch 94/100\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 2.0206 - accuracy: 0.3405 - val_loss: 47514.3906 - val_accuracy: 0.3216\n",
      "Epoch 95/100\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 2.0198 - accuracy: 0.3405 - val_loss: 47514.3906 - val_accuracy: 0.3216\n",
      "Epoch 96/100\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 2.0189 - accuracy: 0.3405 - val_loss: 47514.3906 - val_accuracy: 0.3216\n",
      "Epoch 97/100\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 2.0182 - accuracy: 0.3405 - val_loss: 47514.3867 - val_accuracy: 0.3216\n",
      "Epoch 98/100\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 2.0175 - accuracy: 0.3405 - val_loss: 47514.3867 - val_accuracy: 0.3216\n",
      "Epoch 99/100\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 2.0167 - accuracy: 0.3405 - val_loss: 47514.3867 - val_accuracy: 0.3216\n",
      "Epoch 100/100\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 2.0160 - accuracy: 0.3405 - val_loss: 47514.3867 - val_accuracy: 0.3216\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(trainx, trainy, epochs=100, validation_data=(testx,testy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras_tuner as kt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(hp):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(500, activation='relu', input_dim = 9))\n",
    "    model.add(Dense(250, activation='relu'))\n",
    "    model.add(Dense(125, activation='relu'))\n",
    "    model.add(Dense(100, activation='relu'))\n",
    "    model.add(Dense(56, activation='relu'))\n",
    "    model.add(Dense(28, activation='relu'))\n",
    "    model.add(Dense(14,activation='softmax'))\n",
    "\n",
    "    optimizers = hp.Choice('optimizer', values = ['adam', 'sgd', 'adagrad', 'adadelta', 'rmsprop'])\n",
    "    model.compile(optimizer=optimizers, loss='sparse_categorical_crossentropy')\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reloading Tuner from .\\untitled_project\\tuner0.json\n"
     ]
    }
   ],
   "source": [
    "tuner = kt.RandomSearch(\n",
    "    build_model,\n",
    "    objective='val_accuracy',\n",
    "    max_trials=5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "tuner.search(trainx, trainy, epochs = 5, validation_data = (testx,testy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results summary\n",
      "Results in .\\untitled_project\n",
      "Showing 10 best trials\n",
      "Objective(name=\"val_accuracy\", direction=\"max\")\n",
      "\n",
      "Trial 2 summary\n",
      "Hyperparameters:\n",
      "optimizer: adadelta\n",
      "Score: 85813616.0\n",
      "\n",
      "Trial 3 summary\n",
      "Hyperparameters:\n",
      "optimizer: adam\n",
      "Score: 12967.2724609375\n",
      "\n",
      "Trial 1 summary\n",
      "Hyperparameters:\n",
      "optimizer: adagrad\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras_tuner\\engine\\base_tuner.py\", line 270, in _try_run_and_update_trial\n",
      "    self._run_and_update_trial(trial, *fit_args, **fit_kwargs)\n",
      "  File \"c:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras_tuner\\engine\\base_tuner.py\", line 235, in _run_and_update_trial\n",
      "    results = self.run_trial(trial, *fit_args, **fit_kwargs)\n",
      "  File \"c:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras_tuner\\engine\\tuner.py\", line 287, in run_trial\n",
      "    obj_value = self._build_and_fit_model(trial, *args, **copied_kwargs)\n",
      "  File \"c:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras_tuner\\engine\\tuner.py\", line 214, in _build_and_fit_model\n",
      "    results = self.hypermodel.fit(hp, model, *args, **kwargs)\n",
      "  File \"c:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras_tuner\\engine\\hypermodel.py\", line 144, in fit\n",
      "    return model.fit(*args, **kwargs)\n",
      "  File \"c:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 70, in error_handler\n",
      "    raise e.with_traceback(filtered_tb) from None\n",
      "  File \"C:\\Users\\DELL\\AppData\\Local\\Temp\\__autograph_generated_file5c3g3h8r.py\", line 15, in tf__train_function\n",
      "    retval_ = ag__.converted_call(ag__.ld(step_function), (ag__.ld(self), ag__.ld(iterator)), None, fscope)\n",
      "ValueError: in user code:\n",
      "\n",
      "    File \"c:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 1338, in train_function  *\n",
      "        return step_function(self, iterator)\n",
      "    File \"c:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 1322, in step_function  **\n",
      "        outputs = model.distribute_strategy.run(run_step, args=(data,))\n",
      "    File \"c:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 1303, in run_step  **\n",
      "        outputs = model.train_step(data)\n",
      "    File \"c:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 1082, in train_step\n",
      "        self._validate_target_and_loss(y, loss)\n",
      "    File \"c:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 1046, in _validate_target_and_loss\n",
      "        raise ValueError(\n",
      "\n",
      "    ValueError: No loss found. You may have forgotten to provide a `loss` argument in the `compile()` method.\n",
      "\n",
      "\n",
      "\n",
      "Trial 0 summary\n",
      "Hyperparameters:\n",
      "optimizer: rmsprop\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras_tuner\\engine\\base_tuner.py\", line 270, in _try_run_and_update_trial\n",
      "    self._run_and_update_trial(trial, *fit_args, **fit_kwargs)\n",
      "  File \"c:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras_tuner\\engine\\base_tuner.py\", line 235, in _run_and_update_trial\n",
      "    results = self.run_trial(trial, *fit_args, **fit_kwargs)\n",
      "  File \"c:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras_tuner\\engine\\tuner.py\", line 287, in run_trial\n",
      "    obj_value = self._build_and_fit_model(trial, *args, **copied_kwargs)\n",
      "  File \"c:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras_tuner\\engine\\tuner.py\", line 214, in _build_and_fit_model\n",
      "    results = self.hypermodel.fit(hp, model, *args, **kwargs)\n",
      "  File \"c:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras_tuner\\engine\\hypermodel.py\", line 144, in fit\n",
      "    return model.fit(*args, **kwargs)\n",
      "  File \"c:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 70, in error_handler\n",
      "    raise e.with_traceback(filtered_tb) from None\n",
      "  File \"C:\\Users\\DELL\\AppData\\Local\\Temp\\__autograph_generated_file5c3g3h8r.py\", line 15, in tf__train_function\n",
      "    retval_ = ag__.converted_call(ag__.ld(step_function), (ag__.ld(self), ag__.ld(iterator)), None, fscope)\n",
      "ValueError: in user code:\n",
      "\n",
      "    File \"c:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 1338, in train_function  *\n",
      "        return step_function(self, iterator)\n",
      "    File \"c:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 1322, in step_function  **\n",
      "        outputs = model.distribute_strategy.run(run_step, args=(data,))\n",
      "    File \"c:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 1303, in run_step  **\n",
      "        outputs = model.train_step(data)\n",
      "    File \"c:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 1082, in train_step\n",
      "        self._validate_target_and_loss(y, loss)\n",
      "    File \"c:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 1046, in _validate_target_and_loss\n",
      "        raise ValueError(\n",
      "\n",
      "    ValueError: No loss found. You may have forgotten to provide a `loss` argument in the `compile()` method.\n",
      "\n",
      "\n",
      "\n",
      "Trial 4 summary\n",
      "Hyperparameters:\n",
      "optimizer: sgd\n",
      "Score: nan\n"
     ]
    }
   ],
   "source": [
    "tuner.results_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tuner.get_best_models(num_models=1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 500)               5000      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 250)               125250    \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 125)               31375     \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 100)               12600     \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 56)                5656      \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 28)                1596      \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 14)                406       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 181883 (710.48 KB)\n",
      "Trainable params: 181883 (710.48 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/100\n",
      "12/12 [==============================] - 2s 24ms/step - loss: 94144624.0000 - val_loss: 80272048.0000\n",
      "Epoch 8/100\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 88716200.0000 - val_loss: 75239504.0000\n",
      "Epoch 9/100\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 83647232.0000 - val_loss: 70488144.0000\n",
      "Epoch 10/100\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 78698704.0000 - val_loss: 66325920.0000\n",
      "Epoch 11/100\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 74171648.0000 - val_loss: 61846060.0000\n",
      "Epoch 12/100\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 69504696.0000 - val_loss: 57363008.0000\n",
      "Epoch 13/100\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 65082424.0000 - val_loss: 53627412.0000\n",
      "Epoch 14/100\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 61313620.0000 - val_loss: 50594084.0000\n",
      "Epoch 15/100\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 58034428.0000 - val_loss: 47604396.0000\n",
      "Epoch 16/100\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 55573456.0000 - val_loss: 46491216.0000\n",
      "Epoch 17/100\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 54433920.0000 - val_loss: 45697828.0000\n",
      "Epoch 18/100\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 53414808.0000 - val_loss: 44922196.0000\n",
      "Epoch 19/100\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 52511724.0000 - val_loss: 44163228.0000\n",
      "Epoch 20/100\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 51600240.0000 - val_loss: 43191120.0000\n",
      "Epoch 21/100\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 50728672.0000 - val_loss: 42513696.0000\n",
      "Epoch 22/100\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 49831340.0000 - val_loss: 41962428.0000\n",
      "Epoch 23/100\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 48945096.0000 - val_loss: 40970220.0000\n",
      "Epoch 24/100\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 48090524.0000 - val_loss: 40176676.0000\n",
      "Epoch 25/100\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 47256632.0000 - val_loss: 39529916.0000\n",
      "Epoch 26/100\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 46433840.0000 - val_loss: 38815236.0000\n",
      "Epoch 27/100\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 45598408.0000 - val_loss: 38047404.0000\n",
      "Epoch 28/100\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 44794652.0000 - val_loss: 37638584.0000\n",
      "Epoch 29/100\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 44065608.0000 - val_loss: 36806420.0000\n",
      "Epoch 30/100\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 43074320.0000 - val_loss: 36152448.0000\n",
      "Epoch 31/100\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 42358916.0000 - val_loss: 35393416.0000\n",
      "Epoch 32/100\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 41617404.0000 - val_loss: 34537152.0000\n",
      "Epoch 33/100\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 40726800.0000 - val_loss: 33810392.0000\n",
      "Epoch 34/100\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 39923340.0000 - val_loss: 33119250.0000\n",
      "Epoch 35/100\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 39144604.0000 - val_loss: 32669994.0000\n",
      "Epoch 36/100\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 38516884.0000 - val_loss: 31952556.0000\n",
      "Epoch 37/100\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 37932720.0000 - val_loss: 31530774.0000\n",
      "Epoch 38/100\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 37330660.0000 - val_loss: 31071570.0000\n",
      "Epoch 39/100\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 36739708.0000 - val_loss: 30394978.0000\n",
      "Epoch 40/100\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 36147868.0000 - val_loss: 29912918.0000\n",
      "Epoch 41/100\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 35578776.0000 - val_loss: 29581476.0000\n",
      "Epoch 42/100\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 35120088.0000 - val_loss: 29327524.0000\n",
      "Epoch 43/100\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 34723444.0000 - val_loss: 28823840.0000\n",
      "Epoch 44/100\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 34274664.0000 - val_loss: 29117012.0000\n",
      "Epoch 45/100\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 33942756.0000 - val_loss: 29803088.0000\n",
      "Epoch 46/100\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 33616548.0000 - val_loss: 27726972.0000\n",
      "Epoch 47/100\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 32947774.0000 - val_loss: 27571086.0000\n",
      "Epoch 48/100\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 32770728.0000 - val_loss: 27366966.0000\n",
      "Epoch 49/100\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 32424658.0000 - val_loss: 27102138.0000\n",
      "Epoch 50/100\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 32157622.0000 - val_loss: 26847840.0000\n",
      "Epoch 51/100\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 31871874.0000 - val_loss: 27040828.0000\n",
      "Epoch 52/100\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 31621118.0000 - val_loss: 26509312.0000\n",
      "Epoch 53/100\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 31297904.0000 - val_loss: 26384422.0000\n",
      "Epoch 54/100\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 31017102.0000 - val_loss: 25876058.0000\n",
      "Epoch 55/100\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 30689834.0000 - val_loss: 25679656.0000\n",
      "Epoch 56/100\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 30395632.0000 - val_loss: 26048774.0000\n",
      "Epoch 57/100\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 30136084.0000 - val_loss: 25305616.0000\n",
      "Epoch 58/100\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 29739410.0000 - val_loss: 24971962.0000\n",
      "Epoch 59/100\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 29455730.0000 - val_loss: 25047020.0000\n",
      "Epoch 60/100\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 29200372.0000 - val_loss: 24499552.0000\n",
      "Epoch 61/100\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 28917922.0000 - val_loss: 24236388.0000\n",
      "Epoch 62/100\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 28591940.0000 - val_loss: 24139276.0000\n",
      "Epoch 63/100\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 28308284.0000 - val_loss: 23708898.0000\n",
      "Epoch 64/100\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 27982980.0000 - val_loss: 23457678.0000\n",
      "Epoch 65/100\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 27666988.0000 - val_loss: 23133408.0000\n",
      "Epoch 66/100\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 27315876.0000 - val_loss: 23019230.0000\n",
      "Epoch 67/100\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 27036296.0000 - val_loss: 22598854.0000\n",
      "Epoch 68/100\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 26683682.0000 - val_loss: 22604556.0000\n",
      "Epoch 69/100\n",
      "12/12 [==============================] - 0s 22ms/step - loss: 26409318.0000 - val_loss: 22183604.0000\n",
      "Epoch 70/100\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 26135810.0000 - val_loss: 21810354.0000\n",
      "Epoch 71/100\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 25733162.0000 - val_loss: 22301308.0000\n",
      "Epoch 72/100\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 25511748.0000 - val_loss: 21281036.0000\n",
      "Epoch 73/100\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 25057112.0000 - val_loss: 21422092.0000\n",
      "Epoch 74/100\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 24799134.0000 - val_loss: 21025892.0000\n",
      "Epoch 75/100\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 24517800.0000 - val_loss: 20494990.0000\n",
      "Epoch 76/100\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 24163466.0000 - val_loss: 20509312.0000\n",
      "Epoch 77/100\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 23831752.0000 - val_loss: 20146696.0000\n",
      "Epoch 78/100\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 23462802.0000 - val_loss: 19571512.0000\n",
      "Epoch 79/100\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 23019044.0000 - val_loss: 19336072.0000\n",
      "Epoch 80/100\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 22746078.0000 - val_loss: 18970522.0000\n",
      "Epoch 81/100\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 22301832.0000 - val_loss: 18734674.0000\n",
      "Epoch 82/100\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 21955566.0000 - val_loss: 18419000.0000\n",
      "Epoch 83/100\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 21623964.0000 - val_loss: 18110592.0000\n",
      "Epoch 84/100\n",
      "12/12 [==============================] - 0s 21ms/step - loss: 21338024.0000 - val_loss: 17845240.0000\n",
      "Epoch 85/100\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 21071314.0000 - val_loss: 17862306.0000\n",
      "Epoch 86/100\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 20948732.0000 - val_loss: 18041816.0000\n",
      "Epoch 87/100\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 20816140.0000 - val_loss: 17432228.0000\n",
      "Epoch 88/100\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 20531004.0000 - val_loss: 17938768.0000\n",
      "Epoch 89/100\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 20441290.0000 - val_loss: 17038244.0000\n",
      "Epoch 90/100\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 20219744.0000 - val_loss: 17596212.0000\n",
      "Epoch 91/100\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 20169268.0000 - val_loss: 16957428.0000\n",
      "Epoch 92/100\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 19935254.0000 - val_loss: 16454741.0000\n",
      "Epoch 93/100\n",
      "12/12 [==============================] - 0s 21ms/step - loss: 19692080.0000 - val_loss: 16387345.0000\n",
      "Epoch 94/100\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 19522080.0000 - val_loss: 17840932.0000\n",
      "Epoch 95/100\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 19569404.0000 - val_loss: 16251757.0000\n",
      "Epoch 96/100\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 19265372.0000 - val_loss: 16074466.0000\n",
      "Epoch 97/100\n",
      "12/12 [==============================] - 0s 19ms/step - loss: 19166664.0000 - val_loss: 15970103.0000\n",
      "Epoch 98/100\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 19013156.0000 - val_loss: 15717524.0000\n",
      "Epoch 99/100\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 18906022.0000 - val_loss: 15509526.0000\n",
      "Epoch 100/100\n",
      "12/12 [==============================] - 0s 20ms/step - loss: 18694968.0000 - val_loss: 16181531.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x24adf3828f0>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(trainx, trainy, epochs=100, initial_epoch=6, batch_size=72, validation_data=(testx,testy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
